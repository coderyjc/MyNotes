## 01-环境搭建

三台节点：

- 主节点Master
- 从节点slave1/2（配置slaves文件）

节点可以动态删除和增加

### 01 本地源YUM

系统自带的源更新慢，我们可以从本地源来down数据

比如阿里云或者163

### 02 基础配置-防火墙等

**确保各个节点的防火墙处于关闭状态**

```shell
systemctl stop firewalld # 关闭防火墙
systemctl status firewalld # 查看防火墙状态
```

**主机名与映射**

```shell
hostnamectl set-hostname <hostname> # 修改主机名
bash # 立即生效
vim /etc/hosts #添加映射
```

<img src="R:\GITHUB\MyNotes\_Typora\BigData\竞赛培训笔记\竞赛培训笔记.imgs\image-20210417073537623.png" alt="image-20210417073537623" style="zoom: 67%;" />

主机名分别为 master/slave1/slave2

**时间同步**

主机之间传送数据，需要配置统一的时区

时区选择`tzselect`

<img src="R:\GITHUB\MyNotes\_Typora\BigData\竞赛培训笔记\竞赛培训笔记.imgs\image-20210417074018545.png" alt="image-20210417074018545" style="zoom: 80%;" />

tzselect命令是告诉我们时区的写法，并不会生效，所以我们应该手动使其生效

```shell
TZ='Asia/Shanghai'; export TZ
```

**时间同步协议NTP**

提供准确的时间，同步整个系统的时间

安装ntp

```shell
yum install -y ntp
```

让master作为时钟源

```shell
# 文件/etc/ntp.conf
# server 210.72.145.44 中国国家授时中心的IP

server 127.127.1.0 # local clock
fudge 127.127.1.0 # stratum 1
```

slave 手动同步时间

```shell
ntpdate master # 同步master上的时间
```

定时任务命令`crontab`

<img src="R:\GITHUB\MyNotes\_Typora\BigData\竞赛培训笔记\竞赛培训笔记.imgs\image-20210417074815007.png" alt="image-20210417074815007" style="zoom:67%;" />

要求每10分钟同步一次时间

<img src="R:\GITHUB\MyNotes\_Typora\BigData\竞赛培训笔记\竞赛培训笔记.imgs\image-20210417075110019.png" alt="image-20210417075110019" style="zoom:67%;" />

### 03 远程登陆-SSH

用于主从节点之间的通信

1. 输入ssh-keygen，一路默认回车，也可以直接执行：

ssh-keygen -t dsa -P '' -f ~/.ssh/id_dsa

2. 将生成的公钥文件复制到授权列表

cat ./id_rsa.pub >> authorized_keys

3. 将该授权文件authorized keys文件复制到slaves中的节点

scp authorized_keys root@slave1：~/.ssh/

**配置免密登录**

目的：将.ssh/id_rsa放到其他机器上的authorized_key中

检查免密登录是否设置成功:

ssh slave1

只需要第一次输入密码

选择那种加密算法？

RSA与DSA都是非对称加密算法，相同密钥长度RSA算法和DSA算法安全性相当。

DSA只能用于数字签名，而无法用于加密（某些扩展可以支持加密）；RSA即可作为数字签名，也可以作为加密算法（未被完全攻破、暴力破解）

### 04 语言环境-JAVA


创建工作目录：mkdir -p /usr/java

下载软件：wget http://xxxx/jdk-8u221-linux-x64.tar.gz

解压：tar -zxvf jdk-8u221-linux-x64.tar.gz -C /usr/java/

环境变量：/etc/profile

```shell
# /etc/profile
export JAVA HOME=/usr/java/jdk1.8.0221
export PATH=$PATH:$JAVA HOME/bin
# 注意生效变量文件
source /etc/profile
```

### 05 协调系统-ZK

<img src="R:\GITHUB\MyNotes\_Typora\BigData\竞赛培训笔记\竞赛培训笔记.imgs\image-20210417154323226.png" alt="image-20210417154323226" style="zoom:80%;" />

下载解压zoo安装包`/usr/zookeeper`

配置环境变量 `/etc/profile`

```shell
export ZOOKEEPER_HOME=/usr/zookeeper/zookeeper-3.4.14
PATH=$PATH:$ZOOKEEPER_HOME/bin
```

zoo安装：

配置文件：`zoo.cfg`

```shell
tickTime=2000 # 心跳间隔, 确认主机存活
initLimit=10 # 最大初始时间限制10倍心跳 > 10倍心跳时间内没有发送存活信息就认为是死掉了
syncLimit=5 # 请求应答时常5倍心跳

dataDir=/usr/zookeeper/zookeeper-3.4.14/zkdata # 数据目录
clientPort=2181 # 客户端、服务端连接端口
dataDir=/usr/zookeeper/zookeeper-3.4.14/zkdatalog # 日志目录

# 集群列表
server.1=master:2888:3888
server.2=slave1:2888:3888
server.3=slave2:2888:3888 # 2888和3888是固定端口，无需更改
```

配置的dataDir指定的目录下面创建一个myid文件。

里面是一个数字，用来标识当前的主机

**conf/zoo.cfg:server.X中X是什么，在myid中就输入什么**

<img src="R:\GITHUB\MyNotes\_Typora\BigData\竞赛培训笔记\竞赛培训笔记.imgs\image-20210417153904763.png" alt="image-20210417153904763" style="zoom:67%;" />

在每个节点上启动Zookeeper服务脚本

```bash
bin/skServer.sh start # 启动服务
bin/skServer.sh statue # 查看状态
```

结果应该是：一个节点是leader，其他的是follower

<img src="R:\GITHUB\MyNotes\_Typora\BigData\竞赛培训笔记\竞赛培训笔记.imgs\image-20210417154240181.png" alt="image-20210417154240181" style="zoom:67%;" />



### 06 集群安装-HADOOP



下载解压Hadoop安装包，工作路径：/usr/hadoop，注意修改环境变量/etc/profile。

环境变量:

```shell
export HADOOP_HOME=/usr/hadoop/hadoop-2.7.7
export PATH=$HADOOP_HOME/bin:$HADOOP_HOME/sbin
```

- hadoop-env.sh 用来定义Hadoop运行环境相关的配置信息；
  - `exportJAVA_HOME=/usr/java/jdk1.8.0_221`

- core-site.xml 定义系统级别的参数(全局参数)，包括HDFS URL、Hadoop临时目录等；

  ```xml
  <!--集群全局参数-->
  fs.default.name // NN节点地址与端口号
  hdfs://master:9000
  
  <!--hadoop临时目录用来存放临时文件-->
  hadoop.tmp.dir
  /usr/hadoop/hadoop-2.7.7/hdfs/tmp
  
  <!--SNN检查NN日志时间间隔(秒)-->
  fs.checkpoint.period
  3600
  ```

  

- hdfs-site.xml 定义名称节点、数据节点的存放位置、文本副本的个数、文件读取权限等；

  ```xml
  <!--hdfs-site.xml-->
  
  dfs.replication // 指定hdfs保存数据的副本数量
  
  dfs.namenode.name.dir // hdfs中NN的本地存储位置
  file:/usr/hadoop/hadoop-2.7.7/hdfs/name
  
  dfs.datanode.data.dir // 指定hdfs中DN本地存储位置
  file:/usr/hadoop/hadoop-2.7.7/hdfs/data
  
  dfs.namenode.secondary.http-address // 定义HDFS对应的HTTP服务器地址和端口
  
  dfs.webhdfs.enabled // 开启webhdfs,允许文件访问修改等操作
  ```

- mapred-site.xml MapReduce参数

  ```xml
  mapreduce.framework.name
  yarn
  <!--取值为yarn\local\classic其中之一, 选择yarn,使用yarn实现资源分配-->
  ```

- yarn-site.xml 集群资源管理系统参数配置

  ```xml
  <!--yarn-site.xml-->
  
  
  ```

- master文件，slaves文件

- 格式化并启动Hadoop

