---
annotation-target: 深度学习入门：基于Python的理论与实现.pdf
---


>%%
>```annotation-json
>{"created":"2024-02-29T11:55:06.254Z","updated":"2024-02-29T11:55:06.254Z","document":{"title":"%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","link":[{"href":"urn:x-pdf:3cd36d714d46ee45a1ce3205394700f6"},{"href":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf"}],"documentFingerprint":"3cd36d714d46ee45a1ce3205394700f6"},"uri":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","target":[{"source":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","selector":[{"type":"TextPositionSelector","start":31397,"end":31421},{"type":"TextQuoteSelector","exact":"感知机也是作为神经网络（深度学习）的起源的算法。","prefix":"7年提出来的。为何我们现在还要学习这一很久以前就有的算法呢？因为","suffix":"因此，学习感知机的构造也就是学习通向神经网络和深度学习的一种重要"}]}]}
>```
>%%
>*%%PREFIX%%7年提出来的。为何我们现在还要学习这一很久以前就有的算法呢？因为%%HIGHLIGHT%% ==感知机也是作为神经网络（深度学习）的起源的算法。== %%POSTFIX%%因此，学习感知机的构造也就是学习通向神经网络和深度学习的一种重要*
>%%LINK%%[[#^6ctyi5dblhh|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^6ctyi5dblhh



>%%
>```annotation-json
>{"created":"2024-02-29T11:57:43.195Z","updated":"2024-02-29T11:57:43.195Z","document":{"title":"%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","link":[{"href":"urn:x-pdf:3cd36d714d46ee45a1ce3205394700f6"},{"href":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf"}],"documentFingerprint":"3cd36d714d46ee45a1ce3205394700f6"},"uri":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","target":[{"source":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","selector":[{"type":"TextPositionSelector","start":31883,"end":31918},{"type":"TextQuoteSelector","exact":"只有当这个总和超过了某个界限值时，才会输出1。这也称为“神经元被激活”","prefix":"机22（w1x1、w2x2）。神经元会计算传送过来的信号的总和，","suffix":" 。这里将这个界限值称为阈值，用符号θ表示。图2-1 有两个输入"}]}]}
>```
>%%
>*%%PREFIX%%机22（w1x1、w2x2）。神经元会计算传送过来的信号的总和，%%HIGHLIGHT%% ==只有当这个总和超过了某个界限值时，才会输出1。这也称为“神经元被激活”== %%POSTFIX%%。这里将这个界限值称为阈值，用符号θ表示。图2-1 有两个输入*
>%%LINK%%[[#^o1rxcnt6q5|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^o1rxcnt6q5


>%%
>```annotation-json
>{"created":"2024-02-29T12:53:47.771Z","updated":"2024-02-29T12:53:47.771Z","document":{"title":"%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","link":[{"href":"urn:x-pdf:3cd36d714d46ee45a1ce3205394700f6"},{"href":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf"}],"documentFingerprint":"3cd36d714d46ee45a1ce3205394700f6"},"uri":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","target":[{"source":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","selector":[{"type":"TextPositionSelector","start":33028,"end":33105},{"type":"TextQuoteSelector","exact":"。而机器学习的课题就是将这个决定参数值的工作交由计算机自动进行。学习是确定合适的参数的过程，而人要做的是思考感知机的构造（模型），并把训练数据交给计算机。","prefix":"们人。我们看着真值表这种“训练数据”，人工考虑（想到）了参数的值","suffix":"如上所示，我们已经知道使用感知机可以表示与门、与非门、或门的逻辑"}]}]}
>```
>%%
>*%%PREFIX%%们人。我们看着真值表这种“训练数据”，人工考虑（想到）了参数的值%%HIGHLIGHT%% ==。而机器学习的课题就是将这个决定参数值的工作交由计算机自动进行。学习是确定合适的参数的过程，而人要做的是思考感知机的构造（模型），并把训练数据交给计算机。== %%POSTFIX%%如上所示，我们已经知道使用感知机可以表示与门、与非门、或门的逻辑*
>%%LINK%%[[#^7qugn2qtnyp|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^7qugn2qtnyp


>%%
>```annotation-json
>{"created":"2024-02-29T13:05:19.192Z","updated":"2024-02-29T13:05:19.192Z","document":{"title":"%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","link":[{"href":"urn:x-pdf:3cd36d714d46ee45a1ce3205394700f6"},{"href":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf"}],"documentFingerprint":"3cd36d714d46ee45a1ce3205394700f6"},"uri":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","target":[{"source":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","selector":[{"type":"TextPositionSelector","start":34581,"end":34633},{"type":"TextQuoteSelector","exact":"w1和w2是控制输入信号的重要性的参数，而偏置是调整神经元被激活的容易程度（输出信号为1的程度）的参数。","prefix":"b，但是请注意，偏置和权重w1、w2的作用是不一样的。具体地说，","suffix":"比如，若b为−0.1，则只要输入信号的加权总和超过0.1，神经元"}]}]}
>```
>%%
>*%%PREFIX%%b，但是请注意，偏置和权重w1、w2的作用是不一样的。具体地说，%%HIGHLIGHT%% ==w1和w2是控制输入信号的重要性的参数，而偏置是调整神经元被激活的容易程度（输出信号为1的程度）的参数。== %%POSTFIX%%比如，若b为−0.1，则只要输入信号的加权总和超过0.1，神经元*
>%%LINK%%[[#^4h34o9eo82g|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^4h34o9eo82g


>%%
>```annotation-json
>{"created":"2024-02-29T13:37:17.321Z","updated":"2024-02-29T13:37:17.321Z","document":{"title":"%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","link":[{"href":"urn:x-pdf:3cd36d714d46ee45a1ce3205394700f6"},{"href":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf"}],"documentFingerprint":"3cd36d714d46ee45a1ce3205394700f6"},"uri":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","target":[{"source":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","selector":[{"type":"TextPositionSelector","start":36810,"end":36841},{"type":"TextQuoteSelector","exact":"单层感知机无法表示异或门”或者“单层感知机无法分离非线性空间”","prefix":"或门！x2x1y2.4节讲到的感知机的局限性，严格地讲，应该是“","suffix":"。接下来，我们将看到通过组合感知机（叠加层）就可以实现异或门。异"}]}]}
>```
>%%
>*%%PREFIX%%或门！x2x1y2.4节讲到的感知机的局限性，严格地讲，应该是“%%HIGHLIGHT%% ==单层感知机无法表示异或门”或者“单层感知机无法分离非线性空间”== %%POSTFIX%%。接下来，我们将看到通过组合感知机（叠加层）就可以实现异或门。异*
>%%LINK%%[[#^hc2mbu7ny4b|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^hc2mbu7ny4b


>%%
>```annotation-json
>{"created":"2024-02-29T13:40:47.916Z","updated":"2024-02-29T13:40:47.916Z","document":{"title":"%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","link":[{"href":"urn:x-pdf:3cd36d714d46ee45a1ce3205394700f6"},{"href":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf"}],"documentFingerprint":"3cd36d714d46ee45a1ce3205394700f6"},"uri":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","target":[{"source":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","selector":[{"type":"TextPositionSelector","start":38104,"end":38128},{"type":"TextQuoteSelector","exact":"过叠加层（加深层），感知机能进行更加灵活的表示。","prefix":"单层感知机无法表示的东西，通过增加一层就可以解决”。也就是说，通","suffix":"2.6  从与非门到计算机  352.6 从与非门到计算机多层感"}]}]}
>```
>%%
>*%%PREFIX%%单层感知机无法表示的东西，通过增加一层就可以解决”。也就是说，通%%HIGHLIGHT%% ==过叠加层（加深层），感知机能进行更加灵活的表示。== %%POSTFIX%%2.6  从与非门到计算机  352.6 从与非门到计算机多层感*
>%%LINK%%[[#^s9cete2dp68|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^s9cete2dp68


>%%
>```annotation-json
>{"created":"2024-02-29T13:49:25.026Z","updated":"2024-02-29T13:49:25.026Z","document":{"title":"%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","link":[{"href":"urn:x-pdf:3cd36d714d46ee45a1ce3205394700f6"},{"href":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf"}],"documentFingerprint":"3cd36d714d46ee45a1ce3205394700f6"},"uri":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","target":[{"source":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","selector":[{"type":"TextPositionSelector","start":39210,"end":39224},{"type":"TextQuoteSelector","exact":"感知机将权重和偏置设定为参数","prefix":"是具有输入和输出的算法。给定一个输入后，将输出一个既定的值。• ","suffix":"。• 使用感知机可以表示与门和或门等逻辑电路。• 异或门无法通过"}]}]}
>```
>%%
>*%%PREFIX%%是具有输入和输出的算法。给定一个输入后，将输出一个既定的值。•%%HIGHLIGHT%% ==感知机将权重和偏置设定为参数== %%POSTFIX%%。• 使用感知机可以表示与门和或门等逻辑电路。• 异或门无法通过*
>%%LINK%%[[#^jzw7c6ieem|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^jzw7c6ieem


>%%
>```annotation-json
>{"created":"2024-02-29T13:50:33.293Z","updated":"2024-02-29T13:50:33.293Z","document":{"title":"%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","link":[{"href":"urn:x-pdf:3cd36d714d46ee45a1ce3205394700f6"},{"href":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf"}],"documentFingerprint":"3cd36d714d46ee45a1ce3205394700f6"},"uri":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","target":[{"source":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","selector":[{"type":"TextPositionSelector","start":39546,"end":39578},{"type":"TextQuoteSelector","exact":"经网络的一个重要性质是它可以自动地从数据中学习到合适的权重参数。","prefix":"合适的权重。神经网络的出现就是为了解决刚才的坏消息。具体地讲，神","suffix":"本章中，我们会先介绍神经网络的概要，然后重点关注神经网络进行识别"}]}]}
>```
>%%
>*%%PREFIX%%合适的权重。神经网络的出现就是为了解决刚才的坏消息。具体地讲，神%%HIGHLIGHT%% ==经网络的一个重要性质是它可以自动地从数据中学习到合适的权重参数。== %%POSTFIX%%本章中，我们会先介绍神经网络的概要，然后重点关注神经网络进行识别*
>%%LINK%%[[#^f78dtzy6v6d|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^f78dtzy6v6d


>%%
>```annotation-json
>{"created":"2024-02-29T13:59:35.260Z","updated":"2024-02-29T13:59:35.260Z","document":{"title":"%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","link":[{"href":"urn:x-pdf:3cd36d714d46ee45a1ce3205394700f6"},{"href":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf"}],"documentFingerprint":"3cd36d714d46ee45a1ce3205394700f6"},"uri":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","target":[{"source":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","selector":[{"type":"TextPositionSelector","start":40866,"end":40901},{"type":"TextQuoteSelector","exact":"h（x）函数会将输入信号的总和转换为输出信号，这种函数一般称为激活函数","prefix":"（ 3.3）做的是相同的事情。3.1.3 激活函数登场刚才登场的","suffix":"（activation function）。如“激活”一词所示，"}]}]}
>```
>%%
>*%%PREFIX%%（ 3.3）做的是相同的事情。3.1.3 激活函数登场刚才登场的%%HIGHLIGHT%% ==h（x）函数会将输入信号的总和转换为输出信号，这种函数一般称为激活函数== %%POSTFIX%%（activation function）。如“激活”一词所示，*
>%%LINK%%[[#^92p5bow2d77|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^92p5bow2d77


>%%
>```annotation-json
>{"created":"2024-02-29T14:21:11.993Z","updated":"2024-02-29T14:21:11.993Z","document":{"title":"%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","link":[{"href":"urn:x-pdf:3cd36d714d46ee45a1ce3205394700f6"},{"href":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf"}],"documentFingerprint":"3cd36d714d46ee45a1ce3205394700f6"},"uri":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","target":[{"source":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","selector":[{"type":"TextPositionSelector","start":41531,"end":41550},{"type":"TextQuoteSelector","exact":"激活函数是连接感知机和神经网络的桥梁。","prefix":"yh()a  第3章 神经网络42下面，我们将仔细介绍激活函数。","suffix":"A本书在使用“感知机”一词时，没有严格统一它所指的算法。一般而言"}]}]}
>```
>%%
>*%%PREFIX%%yh()a  第3章 神经网络42下面，我们将仔细介绍激活函数。%%HIGHLIGHT%% ==激活函数是连接感知机和神经网络的桥梁。== %%POSTFIX%%A本书在使用“感知机”一词时，没有严格统一它所指的算法。一般而言*
>%%LINK%%[[#^0o5thr4az3ul|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^0o5thr4az3ul


>%%
>```annotation-json
>{"created":"2024-02-29T14:22:22.081Z","updated":"2024-02-29T14:22:22.081Z","document":{"title":"%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","link":[{"href":"urn:x-pdf:3cd36d714d46ee45a1ce3205394700f6"},{"href":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf"}],"documentFingerprint":"3cd36d714d46ee45a1ce3205394700f6"},"uri":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","target":[{"source":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","selector":[{"type":"TextPositionSelector","start":41578,"end":41662},{"type":"TextQuoteSelector","exact":"一般而言，“朴素感知机”是指单层网络，指的是激活函数使用了阶跃函数A 的模型。“多层感知机”是指神经网络，即使用sigmoid 函数（后述）等平滑的激活函数的多层网络。","prefix":"的桥梁。A本书在使用“感知机”一词时，没有严格统一它所指的算法。","suffix":"3.2 激活函数式（3.3）表示的激活函数以阈值为界，一旦输入超"}]}]}
>```
>%%
>*%%PREFIX%%的桥梁。A本书在使用“感知机”一词时，没有严格统一它所指的算法。%%HIGHLIGHT%% ==一般而言，“朴素感知机”是指单层网络，指的是激活函数使用了阶跃函数A 的模型。“多层感知机”是指神经网络，即使用sigmoid 函数（后述）等平滑的激活函数的多层网络。== %%POSTFIX%%3.2 激活函数式（3.3）表示的激活函数以阈值为界，一旦输入超*
>%%LINK%%[[#^wupkvt0q2ne|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^wupkvt0q2ne


>%%
>```annotation-json
>{"created":"2024-02-29T14:24:50.797Z","updated":"2024-02-29T14:24:50.797Z","document":{"title":"%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","link":[{"href":"urn:x-pdf:3cd36d714d46ee45a1ce3205394700f6"},{"href":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf"}],"documentFingerprint":"3cd36d714d46ee45a1ce3205394700f6"},"uri":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","target":[{"source":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","selector":[{"type":"TextPositionSelector","start":42110,"end":42139},{"type":"TextQuoteSelector","exact":"神经网络中用sigmoid函数作为激活函数，进行信号的转换","prefix":"1.0)=0.731...、h(2.0)=0.880...这样。","suffix":"，转换后的A  阶跃函数是指一旦输入超过阈值，就切换输出的函数。"}]}]}
>```
>%%
>*%%PREFIX%%1.0)=0.731...、h(2.0)=0.880...这样。%%HIGHLIGHT%% ==神经网络中用sigmoid函数作为激活函数，进行信号的转换== %%POSTFIX%%，转换后的A  阶跃函数是指一旦输入超过阈值，就切换输出的函数。*
>%%LINK%%[[#^5xxo2jpc3yi|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^5xxo2jpc3yi


>%%
>```annotation-json
>{"created":"2024-02-29T14:25:08.613Z","updated":"2024-02-29T14:25:08.613Z","document":{"title":"%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","link":[{"href":"urn:x-pdf:3cd36d714d46ee45a1ce3205394700f6"},{"href":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf"}],"documentFingerprint":"3cd36d714d46ee45a1ce3205394700f6"},"uri":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","target":[{"source":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","selector":[{"type":"TextPositionSelector","start":42201,"end":42237},{"type":"TextQuoteSelector","exact":"上一章介绍的感知机和接下来要介绍的神经网络的主要区别就在于这个激活函数。","prefix":"数。3.2  激活函数  43信号被传送给下一个神经元。实际上，","suffix":"其他方面，比如神经元的多层连接的构造、信号的传递方法等，基本上和"}]}]}
>```
>%%
>*%%PREFIX%%数。3.2  激活函数  43信号被传送给下一个神经元。实际上，%%HIGHLIGHT%% ==上一章介绍的感知机和接下来要介绍的神经网络的主要区别就在于这个激活函数。== %%POSTFIX%%其他方面，比如神经元的多层连接的构造、信号的传递方法等，基本上和*
>%%LINK%%[[#^y2z8voxn0t|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^y2z8voxn0t


>%%
>```annotation-json
>{"created":"2024-03-01T14:07:46.434Z","updated":"2024-03-01T14:07:46.434Z","document":{"title":"%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","link":[{"href":"urn:x-pdf:3cd36d714d46ee45a1ce3205394700f6"},{"href":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf"}],"documentFingerprint":"3cd36d714d46ee45a1ce3205394700f6"},"uri":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","target":[{"source":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","selector":[{"type":"TextPositionSelector","start":45124,"end":45157},{"type":"TextQuoteSelector","exact":"sigmoid函数可以返回0.731...、0.880...等实数","prefix":"3章 神经网络48另一个不同点是，相对于阶跃函数只能返回0或1，","suffix":"（这一点和刚才的平滑性有关）。也就是说，感知机中神经元之间流动的"}]}]}
>```
>%%
>*%%PREFIX%%3章 神经网络48另一个不同点是，相对于阶跃函数只能返回0或1，%%HIGHLIGHT%% ==sigmoid函数可以返回0.731...、0.880...等实数== %%POSTFIX%%（这一点和刚才的平滑性有关）。也就是说，感知机中神经元之间流动的*
>%%LINK%%[[#^7jtfphsaivd|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^7jtfphsaivd


>%%
>```annotation-json
>{"created":"2024-03-01T14:07:54.700Z","updated":"2024-03-01T14:07:54.700Z","document":{"title":"%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","link":[{"href":"urn:x-pdf:3cd36d714d46ee45a1ce3205394700f6"},{"href":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf"}],"documentFingerprint":"3cd36d714d46ee45a1ce3205394700f6"},"uri":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","target":[{"source":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","selector":[{"type":"TextPositionSelector","start":45177,"end":45218},{"type":"TextQuoteSelector","exact":"感知机中神经元之间流动的是0或1的二元信号，而神经网络中流动的是连续的实数值信号。","prefix":"、0.880...等实数（这一点和刚才的平滑性有关）。也就是说，","suffix":"如果把这两个函数与水联系起来，则阶跃函数可以比作“竹筒敲石”A，"}]}]}
>```
>%%
>*%%PREFIX%%、0.880...等实数（这一点和刚才的平滑性有关）。也就是说，%%HIGHLIGHT%% ==感知机中神经元之间流动的是0或1的二元信号，而神经网络中流动的是连续的实数值信号。== %%POSTFIX%%如果把这两个函数与水联系起来，则阶跃函数可以比作“竹筒敲石”A，*
>%%LINK%%[[#^hh6tqnkhiv9|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^hh6tqnkhiv9


>%%
>```annotation-json
>{"created":"2024-03-01T14:09:19.170Z","updated":"2024-03-01T14:09:19.170Z","document":{"title":"%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","link":[{"href":"urn:x-pdf:3cd36d714d46ee45a1ce3205394700f6"},{"href":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf"}],"documentFingerprint":"3cd36d714d46ee45a1ce3205394700f6"},"uri":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","target":[{"source":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","selector":[{"type":"TextPositionSelector","start":45426,"end":45460},{"type":"TextQuoteSelector","exact":"“输入小时，输出接近0（为0）；随着输入增大，输出向1靠近（变成1）","prefix":"角看图3-8，可以发现它们具有相似的形状。实际上，两者的结构均是","suffix":"”。也就是说，当输入信号为重要信息时，阶跃函数和sigmoid函"}]}]}
>```
>%%
>*%%PREFIX%%角看图3-8，可以发现它们具有相似的形状。实际上，两者的结构均是%%HIGHLIGHT%% ==“输入小时，输出接近0（为0）；随着输入增大，输出向1靠近（变成1）== %%POSTFIX%%”。也就是说，当输入信号为重要信息时，阶跃函数和sigmoid函*
>%%LINK%%[[#^djgnkjf28b7|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^djgnkjf28b7


>%%
>```annotation-json
>{"created":"2024-03-01T14:12:59.400Z","updated":"2024-03-01T14:12:59.400Z","document":{"title":"%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","link":[{"href":"urn:x-pdf:3cd36d714d46ee45a1ce3205394700f6"},{"href":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf"}],"documentFingerprint":"3cd36d714d46ee45a1ce3205394700f6"},"uri":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","target":[{"source":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","selector":[{"type":"TextPositionSelector","start":46199,"end":46252},{"type":"TextQuoteSelector","exact":"使用线性函数时，无法发挥多层网络带来的优势。因此，为了发挥叠加层所带来的优势，激活函数必须使用非线性函数。","prefix":"3）这一次乘法运算（即没有隐藏层的神经网络）来表示。如本例所示，","suffix":"3.2.7 ReLU函数到目前为止，我们介绍了作为激活函数的阶跃"}]}]}
>```
>%%
>*%%PREFIX%%3）这一次乘法运算（即没有隐藏层的神经网络）来表示。如本例所示，%%HIGHLIGHT%% ==使用线性函数时，无法发挥多层网络带来的优势。因此，为了发挥叠加层所带来的优势，激活函数必须使用非线性函数。== %%POSTFIX%%3.2.7 ReLU函数到目前为止，我们介绍了作为激活函数的阶跃*
>%%LINK%%[[#^dxgoavpt1a|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^dxgoavpt1a


>%%
>```annotation-json
>{"created":"2024-03-01T14:13:54.579Z","updated":"2024-03-01T14:13:54.579Z","document":{"title":"%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","link":[{"href":"urn:x-pdf:3cd36d714d46ee45a1ce3205394700f6"},{"href":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf"}],"documentFingerprint":"3cd36d714d46ee45a1ce3205394700f6"},"uri":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","target":[{"source":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","selector":[{"type":"TextPositionSelector","start":46366,"end":46400},{"type":"TextQuoteSelector","exact":"ReLU函数在输入大于0时，直接输出该值；在输入小于等于0时，输出0","prefix":"使用ReLU（Rectified Linear Unit）函数。","suffix":"（图3-9）。ReLU函数可以表示为下面的式(3.7)。 （3."}]}]}
>```
>%%
>*%%PREFIX%%使用ReLU（Rectified Linear Unit）函数。%%HIGHLIGHT%% ==ReLU函数在输入大于0时，直接输出该值；在输入小于等于0时，输出0== %%POSTFIX%%（图3-9）。ReLU函数可以表示为下面的式(3.7)。 （3.*
>%%LINK%%[[#^mc005i699b|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^mc005i699b


>%%
>```annotation-json
>{"created":"2024-03-05T14:15:01.331Z","updated":"2024-03-05T14:15:01.331Z","document":{"title":"%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","link":[{"href":"urn:x-pdf:3cd36d714d46ee45a1ce3205394700f6"},{"href":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf"}],"documentFingerprint":"3cd36d714d46ee45a1ce3205394700f6"},"uri":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","target":[{"source":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","selector":[{"type":"TextPositionSelector","start":55891,"end":55953},{"type":"TextQuoteSelector","exact":"通过减去输入信号中的最大值（上例中的c），我们发现原本为nan（not a number，不确定）的地方，现在被正确计算了。","prefix":"86e-05,   2.06106005e-09])如该例所示，","suffix":"综上，我们可以像下面这样实现softmax函数。def soft"}]}]}
>```
>%%
>*%%PREFIX%%86e-05,   2.06106005e-09])如该例所示，%%HIGHLIGHT%% ==通过减去输入信号中的最大值（上例中的c），我们发现原本为nan（not a number，不确定）的地方，现在被正确计算了。== %%POSTFIX%%综上，我们可以像下面这样实现softmax函数。def soft*
>%%LINK%%[[#^2rste8t8p0i|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^2rste8t8p0i


>%%
>```annotation-json
>{"created":"2024-03-05T14:16:43.578Z","updated":"2024-03-05T14:16:43.578Z","document":{"title":"%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","link":[{"href":"urn:x-pdf:3cd36d714d46ee45a1ce3205394700f6"},{"href":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf"}],"documentFingerprint":"3cd36d714d46ee45a1ce3205394700f6"},"uri":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","target":[{"source":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","selector":[{"type":"TextPositionSelector","start":56349,"end":56385},{"type":"TextQuoteSelector","exact":"正因为有了这个性质，我们才可以把softmax函数的输出解释为“概率”。","prefix":"出值的总和是1。输出总和为1是softmax函数的一个重要性质。","suffix":"比如，上面的例子可以解释成y[0]的概率是0.018（1.8%）"}]}]}
>```
>%%
>*%%PREFIX%%出值的总和是1。输出总和为1是softmax函数的一个重要性质。%%HIGHLIGHT%% ==正因为有了这个性质，我们才可以把softmax函数的输出解释为“概率”。== %%POSTFIX%%比如，上面的例子可以解释成y[0]的概率是0.018（1.8%）*
>%%LINK%%[[#^ec93wg39dh9|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^ec93wg39dh9


>%%
>```annotation-json
>{"created":"2024-03-05T14:54:55.751Z","updated":"2024-03-05T14:54:55.751Z","document":{"title":"%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","link":[{"href":"urn:x-pdf:3cd36d714d46ee45a1ce3205394700f6"},{"href":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf"}],"documentFingerprint":"3cd36d714d46ee45a1ce3205394700f6"},"uri":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","target":[{"source":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","selector":[{"type":"TextPositionSelector","start":65351,"end":65370},{"type":"TextQuoteSelector","exact":"矩阵的第0维是列方向，第1维是行方向。","prefix":"批数据进行学习，届时也将进行和这里的批处理一样的代码实现。A  ","suffix":"——译者注3.7  小结  793.7 小结本章介绍了神经网络的"}]}]}
>```
>%%
>*%%PREFIX%%批数据进行学习，届时也将进行和这里的批处理一样的代码实现。A%%HIGHLIGHT%% ==矩阵的第0维是列方向，第1维是行方向。== %%POSTFIX%%——译者注3.7  小结  793.7 小结本章介绍了神经网络的*
>%%LINK%%[[#^c5mtiz3bmdn|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^c5mtiz3bmdn


>%%
>```annotation-json
>{"created":"2024-03-06T15:05:32.922Z","updated":"2024-03-06T15:05:32.922Z","document":{"title":"%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","link":[{"href":"urn:x-pdf:3cd36d714d46ee45a1ce3205394700f6"},{"href":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf"}],"documentFingerprint":"3cd36d714d46ee45a1ce3205394700f6"},"uri":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","target":[{"source":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","selector":[{"type":"TextPositionSelector","start":66500,"end":66566},{"type":"TextQuoteSelector","exact":"而机器学习的方法则极力避免人为介入，尝试从收集到的数据中发现答案（模式）。神经网络或深度学习则比以往的机器学习方法更能避免人为介入。","prefix":"—类似这样，人们以自己的经验和直觉为线索，通过反复试验推进工作。","suffix":"现在我们来思考一个具体的问题，比如如何实现数字“5”的识别。数字"}]}]}
>```
>%%
>*%%PREFIX%%—类似这样，人们以自己的经验和直觉为线索，通过反复试验推进工作。%%HIGHLIGHT%% ==而机器学习的方法则极力避免人为介入，尝试从收集到的数据中发现答案（模式）。神经网络或深度学习则比以往的机器学习方法更能避免人为介入。== %%POSTFIX%%现在我们来思考一个具体的问题，比如如何实现数字“5”的识别。数字*
>%%LINK%%[[#^99ql9g57n1e|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^99ql9g57n1e


>%%
>```annotation-json
>{"created":"2024-03-06T15:07:16.284Z","updated":"2024-03-06T15:07:16.284Z","document":{"title":"%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","link":[{"href":"urn:x-pdf:3cd36d714d46ee45a1ce3205394700f6"},{"href":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf"}],"documentFingerprint":"3cd36d714d46ee45a1ce3205394700f6"},"uri":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","target":[{"source":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","selector":[{"type":"TextPositionSelector","start":67597,"end":67640},{"type":"TextQuoteSelector","exact":"端到端是指从一端到另一端的意思，也就是从原始数据（输入）中获得目标结果（输出）的意思。","prefix":"d-to-end machine learning）。这里所说的","suffix":"神经网络的优点是对所有的问题都可以用同样的流程来解决。比如，不管"}]}]}
>```
>%%
>*%%PREFIX%%d-to-end machine learning）。这里所说的%%HIGHLIGHT%% ==端到端是指从一端到另一端的意思，也就是从原始数据（输入）中获得目标结果（输出）的意思。== %%POSTFIX%%神经网络的优点是对所有的问题都可以用同样的流程来解决。比如，不管*
>%%LINK%%[[#^ztc4rgb6lz|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^ztc4rgb6lz


>%%
>```annotation-json
>{"created":"2024-03-06T15:08:32.966Z","updated":"2024-03-06T15:08:32.966Z","document":{"title":"%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","link":[{"href":"urn:x-pdf:3cd36d714d46ee45a1ce3205394700f6"},{"href":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf"}],"documentFingerprint":"3cd36d714d46ee45a1ce3205394700f6"},"uri":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","target":[{"source":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","selector":[{"type":"TextPositionSelector","start":68617,"end":68647},{"type":"TextQuoteSelector","exact":"这个损失函数可以使用任意函数，但一般用均方误差和交叉熵误差等","prefix":"络的学习中所用的指标称为损失函数（loss function）。","suffix":"。损失函数是表示神经网络性能的“恶劣程度”的指标，即当前的神经网"}]}]}
>```
>%%
>*%%PREFIX%%络的学习中所用的指标称为损失函数（loss function）。%%HIGHLIGHT%% ==这个损失函数可以使用任意函数，但一般用均方误差和交叉熵误差等== %%POSTFIX%%。损失函数是表示神经网络性能的“恶劣程度”的指标，即当前的神经网*
>%%LINK%%[[#^oe946jrdrh|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^oe946jrdrh


>%%
>```annotation-json
>{"created":"2024-03-06T15:09:47.842Z","updated":"2024-03-06T15:09:47.842Z","document":{"title":"%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","link":[{"href":"urn:x-pdf:3cd36d714d46ee45a1ce3205394700f6"},{"href":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf"}],"documentFingerprint":"3cd36d714d46ee45a1ce3205394700f6"},"uri":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","target":[{"source":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","selector":[{"type":"TextPositionSelector","start":69272,"end":69307},{"type":"TextQuoteSelector","exact":"将正确解标签表示为1，其他标签表示为0的表示方法称为one-hot表示","prefix":"为1，其他均设为0。这里，标签“2”为 1，表示正确解是“2”。","suffix":"。如式（4.1）所示，均方误差会计算神经网络的输出和正确解监督数"}]}]}
>```
>%%
>*%%PREFIX%%为1，其他均设为0。这里，标签“2”为 1，表示正确解是“2”。%%HIGHLIGHT%% ==将正确解标签表示为1，其他标签表示为0的表示方法称为one-hot表示== %%POSTFIX%%。如式（4.1）所示，均方误差会计算神经网络的输出和正确解监督数*
>%%LINK%%[[#^nlo76i37ly|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^nlo76i37ly


>%%
>```annotation-json
>{"created":"2024-03-07T11:22:25.510Z","updated":"2024-03-07T11:22:25.510Z","document":{"title":"%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","link":[{"href":"urn:x-pdf:3cd36d714d46ee45a1ce3205394700f6"},{"href":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf"}],"documentFingerprint":"3cd36d714d46ee45a1ce3205394700f6"},"uri":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","target":[{"source":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","selector":[{"type":"TextPositionSelector","start":70310,"end":70335},{"type":"TextQuoteSelector","exact":"交叉熵误差的值是由正确解标签所对应的输出结果决定的","prefix":"输出是0.1，则交叉熵误差为−log0.1=2.30。也就是说，","suffix":"。自然对数的图像如图4-3所示。图4-3 自然对数y=logx的"}]}]}
>```
>%%
>*%%PREFIX%%输出是0.1，则交叉熵误差为−log0.1=2.30。也就是说，%%HIGHLIGHT%% ==交叉熵误差的值是由正确解标签所对应的输出结果决定的== %%POSTFIX%%。自然对数的图像如图4-3所示。图4-3 自然对数y=logx的*
>%%LINK%%[[#^w4p8kinl2l|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^w4p8kinl2l


>%%
>```annotation-json
>{"created":"2024-03-07T11:23:23.227Z","updated":"2024-03-07T11:23:23.227Z","document":{"title":"%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","link":[{"href":"urn:x-pdf:3cd36d714d46ee45a1ce3205394700f6"},{"href":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf"}],"documentFingerprint":"3cd36d714d46ee45a1ce3205394700f6"},"uri":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","target":[{"source":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","selector":[{"type":"TextPositionSelector","start":70419,"end":70460},{"type":"TextQuoteSelector","exact":"正确解标签对应的输出越大，式（4.2）的值越接近0；当输出为1时，交叉熵误差为0。","prefix":"-3所示，x等于1时，y为0；随着x向0靠近，y逐渐变小。因此，","suffix":"此外，如果正确解标签对应的输出较小，则式（4.2）的值较大。下面"}]}]}
>```
>%%
>*%%PREFIX%%-3所示，x等于1时，y为0；随着x向0靠近，y逐渐变小。因此，%%HIGHLIGHT%% ==正确解标签对应的输出越大，式（4.2）的值越接近0；当输出为1时，交叉熵误差为0。== %%POSTFIX%%此外，如果正确解标签对应的输出较小，则式（4.2）的值较大。下面*
>%%LINK%%[[#^fczu022nsu|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^fczu022nsu


>%%
>```annotation-json
>{"created":"2024-03-07T11:25:59.723Z","updated":"2024-03-07T11:25:59.723Z","document":{"title":"%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","link":[{"href":"urn:x-pdf:3cd36d714d46ee45a1ce3205394700f6"},{"href":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf"}],"documentFingerprint":"3cd36d714d46ee45a1ce3205394700f6"},"uri":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","target":[{"source":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","selector":[{"type":"TextPositionSelector","start":71294,"end":71315},{"type":"TextQuoteSelector","exact":"把这100个损失函数的总和作为学习的指标。","prefix":"训练数据作为对象。也就是说，如果训练数据有100个的话，我们就要","suffix":"前面介绍的损失函数的例子中考虑的都是针对单个数据的损失函数。如4"}]}]}
>```
>%%
>*%%PREFIX%%训练数据作为对象。也就是说，如果训练数据有100个的话，我们就要%%HIGHLIGHT%% ==把这100个损失函数的总和作为学习的指标。== %%POSTFIX%%前面介绍的损失函数的例子中考虑的都是针对单个数据的损失函数。如4*
>%%LINK%%[[#^xmd53ryrv3|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^xmd53ryrv3


>%%
>```annotation-json
>{"created":"2024-03-07T11:27:19.193Z","updated":"2024-03-07T11:27:19.193Z","document":{"title":"%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","link":[{"href":"urn:x-pdf:3cd36d714d46ee45a1ce3205394700f6"},{"href":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf"}],"documentFingerprint":"3cd36d714d46ee45a1ce3205394700f6"},"uri":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","target":[{"source":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","selector":[{"type":"TextPositionSelector","start":71809,"end":71864},{"type":"TextQuoteSelector","exact":"从60000个训练数据中随机选择100笔，再用这100笔数据进行学习。这种学习方式称为mini-batch学习","prefix":"tch,小批量），然后对每个mini-batch进行学习。比如，","suffix":"。下面我们来编写从训练数据中随机选择指定个数的数据的代码，以进行"}]}]}
>```
>%%
>*%%PREFIX%%tch,小批量），然后对每个mini-batch进行学习。比如，%%HIGHLIGHT%% ==从60000个训练数据中随机选择100笔，再用这100笔数据进行学习。这种学习方式称为mini-batch学习== %%POSTFIX%%。下面我们来编写从训练数据中随机选择指定个数的数据的代码，以进行*
>%%LINK%%[[#^ufp2vqcljfm|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^ufp2vqcljfm


>%%
>```annotation-json
>{"created":"2024-03-07T11:42:06.778Z","updated":"2024-03-07T11:42:06.778Z","document":{"title":"%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","link":[{"href":"urn:x-pdf:3cd36d714d46ee45a1ce3205394700f6"},{"href":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf"}],"documentFingerprint":"3cd36d714d46ee45a1ce3205394700f6"},"uri":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","target":[{"source":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","selector":[{"type":"TextPositionSelector","start":70611,"end":70725},{"type":"TextQuoteSelector","exact":"函数内部在计算np.log时，加上了一个微小值delta。这是因为，当出现np.log(0)时，np.log(0)会变为负无限大的-inf，这样一来就会导致后续计算无法进行。作为保护性对策，添加一个微小值可以防止负无限大的发生。","prefix":"log(y + delta))这里，参数y和t是NumPy数组。","suffix":"下面，我们使用cross_entropy_error(y, t)"}]}]}
>```
>%%
>*%%PREFIX%%log(y + delta))这里，参数y和t是NumPy数组。%%HIGHLIGHT%% ==函数内部在计算np.log时，加上了一个微小值delta。这是因为，当出现np.log(0)时，np.log(0)会变为负无限大的-inf，这样一来就会导致后续计算无法进行。作为保护性对策，添加一个微小值可以防止负无限大的发生。== %%POSTFIX%%下面，我们使用cross_entropy_error(y, t)*
>%%LINK%%[[#^kxmzxybt1xn|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^kxmzxybt1xn


>%%
>```annotation-json
>{"created":"2024-03-07T12:02:11.205Z","text":"我们希望获得连续性变化。","updated":"2024-03-07T12:02:11.205Z","document":{"title":"%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","link":[{"href":"urn:x-pdf:3cd36d714d46ee45a1ce3205394700f6"},{"href":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf"}],"documentFingerprint":"3cd36d714d46ee45a1ce3205394700f6"},"uri":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","target":[{"source":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","selector":[{"type":"TextPositionSelector","start":75230,"end":75290},{"type":"TextQuoteSelector","exact":"即便识别精度有所改善，它的值也不会像32.0123...%这样连续变化，而是变为33%、34%这样的不连续的、离散的值。","prefix":"%，不会出现变化。也就是说，仅仅微调参数，是无法改善识别精度的。","suffix":"而如果把损失函数作为指标，则当前损失函数的值可以表示为0.925"}]}]}
>```
>%%
>*%%PREFIX%%%，不会出现变化。也就是说，仅仅微调参数，是无法改善识别精度的。%%HIGHLIGHT%% ==即便识别精度有所改善，它的值也不会像32.0123...%这样连续变化，而是变为33%、34%这样的不连续的、离散的值。== %%POSTFIX%%而如果把损失函数作为指标，则当前损失函数的值可以表示为0.925*
>%%LINK%%[[#^4nxuyvzpqr7|show annotation]]
>%%COMMENT%%
>我们希望获得连续性变化。
>%%TAGS%%
>
^4nxuyvzpqr7


>%%
>```annotation-json
>{"created":"2024-03-07T12:06:48.691Z","updated":"2024-03-07T12:06:48.691Z","document":{"title":"%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","link":[{"href":"urn:x-pdf:3cd36d714d46ee45a1ce3205394700f6"},{"href":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf"}],"documentFingerprint":"3cd36d714d46ee45a1ce3205394700f6"},"uri":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","target":[{"source":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","selector":[{"type":"TextPositionSelector","start":76850,"end":76883},{"type":"TextQuoteSelector","exact":"使用过小的值会造成计算机出现计算上的问题。这是第一个需要改进的地方","prefix":"）来表示1e-50，就会变成0.0，无法正确表示出来。也就是说，","suffix":"，即将微小值h改为10−4。使用10−4就可以得到正确的结果。第"}]}]}
>```
>%%
>*%%PREFIX%%）来表示1e-50，就会变成0.0，无法正确表示出来。也就是说，%%HIGHLIGHT%% ==使用过小的值会造成计算机出现计算上的问题。这是第一个需要改进的地方== %%POSTFIX%%，即将微小值h改为10−4。使用10−4就可以得到正确的结果。第*
>%%LINK%%[[#^md2znswg4fh|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^md2znswg4fh


>%%
>```annotation-json
>{"created":"2024-03-07T12:07:09.854Z","updated":"2024-03-07T12:07:09.854Z","document":{"title":"%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","link":[{"href":"urn:x-pdf:3cd36d714d46ee45a1ce3205394700f6"},{"href":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf"}],"documentFingerprint":"3cd36d714d46ee45a1ce3205394700f6"},"uri":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","target":[{"source":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","selector":[{"type":"TextPositionSelector","start":77042,"end":77096},{"type":"TextQuoteSelector","exact":"真的导数（真的切线）和上述实现中得到的导数的值在严格意义上并不一致。这个差异的出现是因为h不可能无限接近0。","prefix":"，但上述实现中计算的导数对应的是(x+h)和x之间的斜率。因此，","suffix":"如图4-5所示，数值微分含有误差。为了减小这个误差，我们可以计算"}]}]}
>```
>%%
>*%%PREFIX%%，但上述实现中计算的导数对应的是(x+h)和x之间的斜率。因此，%%HIGHLIGHT%% ==真的导数（真的切线）和上述实现中得到的导数的值在严格意义上并不一致。这个差异的出现是因为h不可能无限接近0。== %%POSTFIX%%如图4-5所示，数值微分含有误差。为了减小这个误差，我们可以计算*
>%%LINK%%[[#^xm17g7i9zj|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^xm17g7i9zj


>%%
>```annotation-json
>{"created":"2024-03-07T12:42:14.182Z","updated":"2024-03-07T12:42:14.182Z","document":{"title":"%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","link":[{"href":"urn:x-pdf:3cd36d714d46ee45a1ce3205394700f6"},{"href":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf"}],"documentFingerprint":"3cd36d714d46ee45a1ce3205394700f6"},"uri":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","target":[{"source":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","selector":[{"type":"TextPositionSelector","start":81910,"end":81940},{"type":"TextQuoteSelector","exact":"一般来说，神经网络（深度学习）中，梯度法主要是指梯度下降法。","prefix":"会变成相同的问题，因此“下降”还是“上升”的差异本质上并不重要。","suffix":"  第4章 神经网络的学习104现在，我们尝试用数学式来表示梯度"}]}]}
>```
>%%
>*%%PREFIX%%会变成相同的问题，因此“下降”还是“上升”的差异本质上并不重要。%%HIGHLIGHT%% ==一般来说，神经网络（深度学习）中，梯度法主要是指梯度下降法。== %%POSTFIX%%第4章 神经网络的学习104现在，我们尝试用数学式来表示梯度*
>%%LINK%%[[#^yjusvf7g57|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^yjusvf7g57


>%%
>```annotation-json
>{"created":"2024-03-07T12:57:21.037Z","updated":"2024-03-07T12:57:21.037Z","document":{"title":"%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","link":[{"href":"urn:x-pdf:3cd36d714d46ee45a1ce3205394700f6"},{"href":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf"}],"documentFingerprint":"3cd36d714d46ee45a1ce3205394700f6"},"uri":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","target":[{"source":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","selector":[{"type":"TextPositionSelector","start":83541,"end":83585},{"type":"TextQuoteSelector","exact":"学习率过大的话，会发散成一个很大的值；反过来，学习率过小的话，基本上没怎么更新就结束了。","prefix":"2.99999994,  3.99999992])实验结果表明，","suffix":"也就是说，设定合适的学习率是一个很重要的问题。像学习率这样的参数"}]}]}
>```
>%%
>*%%PREFIX%%2.99999994,  3.99999992])实验结果表明，%%HIGHLIGHT%% ==学习率过大的话，会发散成一个很大的值；反过来，学习率过小的话，基本上没怎么更新就结束了。== %%POSTFIX%%也就是说，设定合适的学习率是一个很重要的问题。像学习率这样的参数*
>%%LINK%%[[#^wybu7hvfia|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^wybu7hvfia


>%%
>```annotation-json
>{"created":"2024-03-07T12:57:42.879Z","updated":"2024-03-07T12:57:42.879Z","document":{"title":"%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","link":[{"href":"urn:x-pdf:3cd36d714d46ee45a1ce3205394700f6"},{"href":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf"}],"documentFingerprint":"3cd36d714d46ee45a1ce3205394700f6"},"uri":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","target":[{"source":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","selector":[{"type":"TextPositionSelector","start":83608,"end":83732},{"type":"TextQuoteSelector","exact":"像学习率这样的参数称为超参数。这是一种和神经网络的参数（权重和偏置）性质不同的参数。相对于神经网络的权重参数是通过训练数据和学习算法自动获得的，学习率这样的超参数则是人工设定的。一般来说，超参数需要尝试多个值，以便找到一种可以使学习顺利进行的设定。","prefix":"怎么更新就结束了。也就是说，设定合适的学习率是一个很重要的问题。","suffix":"4.4.2 神经网络的梯度神经网络的学习也要求梯度。这里所说的梯"}]}]}
>```
>%%
>*%%PREFIX%%怎么更新就结束了。也就是说，设定合适的学习率是一个很重要的问题。%%HIGHLIGHT%% ==像学习率这样的参数称为超参数。这是一种和神经网络的参数（权重和偏置）性质不同的参数。相对于神经网络的权重参数是通过训练数据和学习算法自动获得的，学习率这样的超参数则是人工设定的。一般来说，超参数需要尝试多个值，以便找到一种可以使学习顺利进行的设定。== %%POSTFIX%%4.4.2 神经网络的梯度神经网络的学习也要求梯度。这里所说的梯*
>%%LINK%%[[#^kp4b43yvdwa|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^kp4b43yvdwa



>%%
>```annotation-json
>{"created":"2024-04-07T03:40:56.072Z","updated":"2024-04-07T03:40:56.072Z","document":{"title":"%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","link":[{"href":"urn:x-pdf:3cd36d714d46ee45a1ce3205394700f6"},{"href":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf"}],"documentFingerprint":"3cd36d714d46ee45a1ce3205394700f6"},"uri":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","target":[{"source":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","selector":[{"type":"TextPositionSelector","start":40311,"end":40371},{"type":"TextQuoteSelector","exact":"b是被称为偏置的参数，用于控制神经元被激活的容易程度；而w1和w2是表示各个信号的权重的参数，用于控制各个信号的重要性。","prefix":"学式来表示图3-2中的感知机，则如式（3.1）所示。 （3.1）","suffix":"顺便提一下，在图3-2的网络中，偏置b并没有被画出来。如果要明确"}]}]}
>```
>%%
>*%%PREFIX%%学式来表示图3-2中的感知机，则如式（3.1）所示。 （3.1）%%HIGHLIGHT%% ==b是被称为偏置的参数，用于控制神经元被激活的容易程度；而w1和w2是表示各个信号的权重的参数，用于控制各个信号的重要性。== %%POSTFIX%%顺便提一下，在图3-2的网络中，偏置b并没有被画出来。如果要明确*
>%%LINK%%[[#^5ay01xszebn|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^5ay01xszebn


>%%
>```annotation-json
>{"created":"2024-04-07T03:50:12.938Z","updated":"2024-04-07T03:50:12.938Z","document":{"title":"%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","link":[{"href":"urn:x-pdf:3cd36d714d46ee45a1ce3205394700f6"},{"href":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf"}],"documentFingerprint":"3cd36d714d46ee45a1ce3205394700f6"},"uri":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","target":[{"source":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","selector":[{"type":"TextPositionSelector","start":44947,"end":44974},{"type":"TextQuoteSelector","exact":"sigmoid函数的平滑性对神经网络的学习具有重要意义","prefix":"输入发生连续性的变化。而阶跃函数以0为界，输出发生急剧性的变化。","suffix":"。3.2  激活函数  47图3-7 sigmoid函数的图形1"}]}]}
>```
>%%
>*%%PREFIX%%输入发生连续性的变化。而阶跃函数以0为界，输出发生急剧性的变化。%%HIGHLIGHT%% ==sigmoid函数的平滑性对神经网络的学习具有重要意义== %%POSTFIX%%。3.2  激活函数  47图3-7 sigmoid函数的图形1*
>%%LINK%%[[#^lbqt1s5xh9c|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^lbqt1s5xh9c


>%%
>```annotation-json
>{"created":"2024-04-07T03:51:27.986Z","updated":"2024-04-07T03:51:27.986Z","document":{"title":"%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","link":[{"href":"urn:x-pdf:3cd36d714d46ee45a1ce3205394700f6"},{"href":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf"}],"documentFingerprint":"3cd36d714d46ee45a1ce3205394700f6"},"uri":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","target":[{"source":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","selector":[{"type":"TextPositionSelector","start":45951,"end":45991},{"type":"TextQuoteSelector","exact":"为什么不能使用线性函数呢？因为使用线性函数的话，加深神经网络的层数就没有意义了。","prefix":"激活函数必须使用非线性函数。换句话说，激活函数不能使用线性函数。","suffix":"线性函数的问题在于，不管如何加深层数，总是存在与之等效的“无隐藏"}]}]}
>```
>%%
>*%%PREFIX%%激活函数必须使用非线性函数。换句话说，激活函数不能使用线性函数。%%HIGHLIGHT%% ==为什么不能使用线性函数呢？因为使用线性函数的话，加深神经网络的层数就没有意义了。== %%POSTFIX%%线性函数的问题在于，不管如何加深层数，总是存在与之等效的“无隐藏*
>%%LINK%%[[#^4dhfj8hq4h|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^4dhfj8hq4h


>%%
>```annotation-json
>{"created":"2024-04-07T08:08:03.107Z","updated":"2024-04-07T08:08:03.107Z","document":{"title":"%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","link":[{"href":"urn:x-pdf:3cd36d714d46ee45a1ce3205394700f6"},{"href":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf"}],"documentFingerprint":"3cd36d714d46ee45a1ce3205394700f6"},"uri":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","target":[{"source":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","selector":[{"type":"TextPositionSelector","start":75664,"end":75729},{"type":"TextQuoteSelector","exact":"sigmoid函数的导数在任何地方都不为0。这对神经网络的学习非常重要。得益于这个斜率不会为0的性质，神经网络的学习得以正确进行。","prefix":"的值）是连续变化的，曲线的斜率（导数）也是连续变化的。也就是说，","suffix":"阶跃函数 sigmoid函数图4-4  阶跃函数和sigmoid"}]}]}
>```
>%%
>*%%PREFIX%%的值）是连续变化的，曲线的斜率（导数）也是连续变化的。也就是说，%%HIGHLIGHT%% ==sigmoid函数的导数在任何地方都不为0。这对神经网络的学习非常重要。得益于这个斜率不会为0的性质，神经网络的学习得以正确进行。== %%POSTFIX%%阶跃函数 sigmoid函数图4-4  阶跃函数和sigmoid*
>%%LINK%%[[#^clm8116u8go|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^clm8116u8go


>%%
>```annotation-json
>{"created":"2024-04-07T09:36:51.191Z","updated":"2024-04-07T09:36:51.191Z","document":{"title":"%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","link":[{"href":"urn:x-pdf:3cd36d714d46ee45a1ce3205394700f6"},{"href":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf"}],"documentFingerprint":"3cd36d714d46ee45a1ce3205394700f6"},"uri":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","target":[{"source":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","selector":[{"type":"TextPositionSelector","start":92516,"end":92565},{"type":"TextQuoteSelector","exact":"过拟合是指，虽然训练数据中的数字图像能被正确辨别，但是不在训练数据中的数字图像却无法被识别的现象。","prefix":"是否能够正确识别训练数据以外的其他数据，即确认是否会发生过拟合。","suffix":"神经网络学习的最初目标是掌握泛化能力，因此，要评价神经网络的泛化"}]}]}
>```
>%%
>*%%PREFIX%%是否能够正确识别训练数据以外的其他数据，即确认是否会发生过拟合。%%HIGHLIGHT%% ==过拟合是指，虽然训练数据中的数字图像能被正确辨别，但是不在训练数据中的数字图像却无法被识别的现象。== %%POSTFIX%%神经网络学习的最初目标是掌握泛化能力，因此，要评价神经网络的泛化*
>%%LINK%%[[#^c21no2rvbh|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^c21no2rvbh


>%%
>```annotation-json
>{"created":"2024-04-08T02:51:35.194Z","updated":"2024-04-08T02:51:35.194Z","document":{"title":"%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","link":[{"href":"urn:x-pdf:3cd36d714d46ee45a1ce3205394700f6"},{"href":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf"}],"documentFingerprint":"3cd36d714d46ee45a1ce3205394700f6"},"uri":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","target":[{"source":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","selector":[{"type":"TextPositionSelector","start":105353,"end":105437},{"type":"TextQuoteSelector","exact":"这个变量mask是由True/False构成的NumPy数组，它会把正向传播时的输入x的元素中小于等于0的地方保存为True，其他地方（大于0的元素）保存为False。","prefix":"        return dxRelu类有实例变量mask。","suffix":"如下例所示，mask变量保存了由True/False构成的Num"}]}]}
>```
>%%
>*%%PREFIX%%return dxRelu类有实例变量mask。%%HIGHLIGHT%% ==这个变量mask是由True/False构成的NumPy数组，它会把正向传播时的输入x的元素中小于等于0的地方保存为True，其他地方（大于0的元素）保存为False。== %%POSTFIX%%如下例所示，mask变量保存了由True/False构成的Num*
>%%LINK%%[[#^1elb5kxd2hki|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^1elb5kxd2hki


>%%
>```annotation-json
>{"created":"2024-04-09T03:41:52.634Z","updated":"2024-04-09T03:41:52.634Z","document":{"title":"%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","link":[{"href":"urn:x-pdf:3cd36d714d46ee45a1ce3205394700f6"},{"href":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf"}],"documentFingerprint":"3cd36d714d46ee45a1ce3205394700f6"},"uri":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","target":[{"source":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","selector":[{"type":"TextPositionSelector","start":118013,"end":118055},{"type":"TextQuoteSelector","exact":"经常会比较数值微分的结果和误差反向传播法的结果，以确认误差反向传播法的实现是否正确。","prefix":"况下不太容易出错。而误差反向传播法的实现很复杂，容易出错。所以，","suffix":"确认数值微分求出的梯度结果和误差反向传播法求出的结果是否一致（严"}]}]}
>```
>%%
>*%%PREFIX%%况下不太容易出错。而误差反向传播法的实现很复杂，容易出错。所以，%%HIGHLIGHT%% ==经常会比较数值微分的结果和误差反向传播法的结果，以确认误差反向传播法的实现是否正确。== %%POSTFIX%%确认数值微分求出的梯度结果和误差反向传播法求出的结果是否一致（严*
>%%LINK%%[[#^bjzvrg8rnd7|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^bjzvrg8rnd7


>%%
>```annotation-json
>{"created":"2024-04-09T03:51:45.696Z","updated":"2024-04-09T03:51:45.696Z","document":{"title":"%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","link":[{"href":"urn:x-pdf:3cd36d714d46ee45a1ce3205394700f6"},{"href":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf"}],"documentFingerprint":"3cd36d714d46ee45a1ce3205394700f6"},"uri":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","target":[{"source":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","selector":[{"type":"TextPositionSelector","start":119098,"end":119142},{"type":"TextQuoteSelector","exact":"数值微分和误差反向传播法的计算结果之间的误差为0是很少见的。这是因为计算机的计算精度有限","prefix":"误差反向传播法求出的梯度是正确的，误差反向传播法的实现没有错误。","suffix":"（比如，32位浮点数）。受到数值精度的限制，刚才的误差一般不会为"}]}]}
>```
>%%
>*%%PREFIX%%误差反向传播法求出的梯度是正确的，误差反向传播法的实现没有错误。%%HIGHLIGHT%% ==数值微分和误差反向传播法的计算结果之间的误差为0是很少见的。这是因为计算机的计算精度有限== %%POSTFIX%%（比如，32位浮点数）。受到数值精度的限制，刚才的误差一般不会为*
>%%LINK%%[[#^yk903kkduz|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^yk903kkduz


>%%
>```annotation-json
>{"created":"2024-04-09T04:16:19.386Z","updated":"2024-04-09T04:16:19.386Z","document":{"title":"%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","link":[{"href":"urn:x-pdf:3cd36d714d46ee45a1ce3205394700f6"},{"href":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf"}],"documentFingerprint":"3cd36d714d46ee45a1ce3205394700f6"},"uri":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","target":[{"source":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","selector":[{"type":"TextPositionSelector","start":123786,"end":123837},{"type":"TextQuoteSelector","exact":"SGD的缺点是，如果函数的形状非均向（anisotropic），比如呈延伸状，搜索的路径就会非常低效。","prefix":"3中，SGD呈“之”字形移动。这是一个相当低效的路径。也就是说，","suffix":"因此，我们需要比单纯朝梯度方向前进的SGD更聪明的方法。SGD低"}]}]}
>```
>%%
>*%%PREFIX%%3中，SGD呈“之”字形移动。这是一个相当低效的路径。也就是说，%%HIGHLIGHT%% ==SGD的缺点是，如果函数的形状非均向（anisotropic），比如呈延伸状，搜索的路径就会非常低效。== %%POSTFIX%%因此，我们需要比单纯朝梯度方向前进的SGD更聪明的方法。SGD低*
>%%LINK%%[[#^9gd0b2ufprw|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^9gd0b2ufprw


>%%
>```annotation-json
>{"created":"2024-04-09T09:57:34.966Z","updated":"2024-04-09T09:57:34.966Z","document":{"title":"%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","link":[{"href":"urn:x-pdf:3cd36d714d46ee45a1ce3205394700f6"},{"href":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf"}],"documentFingerprint":"3cd36d714d46ee45a1ce3205394700f6"},"uri":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","target":[{"source":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","selector":[{"type":"TextPositionSelector","start":128794,"end":128823},{"type":"TextQuoteSelector","exact":"如果想减小权重的值，一开始就将初始值设为较小的值才是正途。","prefix":"值为目的进行学习的方法。通过减小权重参数的值来抑制过拟合的发生。","suffix":"实际上，在这之前的权重初始值都是像0.01 * np.rando"}]}]}
>```
>%%
>*%%PREFIX%%值为目的进行学习的方法。通过减小权重参数的值来抑制过拟合的发生。%%HIGHLIGHT%% ==如果想减小权重的值，一开始就将初始值设为较小的值才是正途。== %%POSTFIX%%实际上，在这之前的权重初始值都是像0.01 * np.rando*
>%%LINK%%[[#^0kixxo3httwk|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^0kixxo3httwk


>%%
>```annotation-json
>{"created":"2024-04-09T09:58:02.216Z","updated":"2024-04-09T09:58:02.216Z","document":{"title":"%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","link":[{"href":"urn:x-pdf:3cd36d714d46ee45a1ce3205394700f6"},{"href":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf"}],"documentFingerprint":"3cd36d714d46ee45a1ce3205394700f6"},"uri":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","target":[{"source":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","selector":[{"type":"TextPositionSelector","start":129012,"end":129061},{"type":"TextQuoteSelector","exact":"为什么不能将权重初始值设成一样的值呢？这是因为在误差反向传播法中，所有的权重值都会进行相同的更新。","prefix":"，将无法正确进行学习。为什么不能将权重初始值设为0呢？严格地说，","suffix":"比如，在2层神经网络中，假设第1层和第2层的权重为0。这样一来，"}]}]}
>```
>%%
>*%%PREFIX%%，将无法正确进行学习。为什么不能将权重初始值设为0呢？严格地说，%%HIGHLIGHT%% ==为什么不能将权重初始值设成一样的值呢？这是因为在误差反向传播法中，所有的权重值都会进行相同的更新。== %%POSTFIX%%比如，在2层神经网络中，假设第1层和第2层的权重为0。这样一来，*
>%%LINK%%[[#^krtdsjxlhj|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^krtdsjxlhj


>%%
>```annotation-json
>{"created":"2024-04-09T09:58:32.756Z","updated":"2024-04-09T09:58:32.756Z","document":{"title":"%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","link":[{"href":"urn:x-pdf:3cd36d714d46ee45a1ce3205394700f6"},{"href":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf"}],"documentFingerprint":"3cd36d714d46ee45a1ce3205394700f6"},"uri":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","target":[{"source":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","selector":[{"type":"TextPositionSelector","start":129263,"end":129302},{"type":"TextQuoteSelector","exact":"了防止“权重均一化”（严格地讲，是为了瓦解权重的对称结构），必须随机生成初始值","prefix":"值（重复的值）。这使得神经网络拥有许多不同的权重的意义丧失了。为","suffix":"。6.2.2 隐藏层的激活值的分布观察隐藏层的激活值A（激活函数"}]}]}
>```
>%%
>*%%PREFIX%%值（重复的值）。这使得神经网络拥有许多不同的权重的意义丧失了。为%%HIGHLIGHT%% ==了防止“权重均一化”（严格地讲，是为了瓦解权重的对称结构），必须随机生成初始值== %%POSTFIX%%。6.2.2 隐藏层的激活值的分布观察隐藏层的激活值A（激活函数*
>%%LINK%%[[#^pd9u6ofl1k|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^pd9u6ofl1k


>%%
>```annotation-json
>{"created":"2024-04-09T10:03:46.888Z","updated":"2024-04-09T10:03:46.888Z","document":{"title":"%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","link":[{"href":"urn:x-pdf:3cd36d714d46ee45a1ce3205394700f6"},{"href":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf"}],"documentFingerprint":"3cd36d714d46ee45a1ce3205394700f6"},"uri":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","target":[{"source":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","selector":[{"type":"TextPositionSelector","start":150232,"end":150303},{"type":"TextQuoteSelector","exact":"假设输入大小为(H,W)，滤波器大小为(FH,FW)，输出大小为(OH,OW)，填充为P，步幅为S。此时，输出大小可通过式(7.1)进行计算。","prefix":"何呢？接下来，我们看一下对于填充和步幅，如何计算输出大小。这里，","suffix":" (7.1)现在，我们使用这个算式，试着做几个计算。例1：图7-"}]}]}
>```
>%%
>*%%PREFIX%%何呢？接下来，我们看一下对于填充和步幅，如何计算输出大小。这里，%%HIGHLIGHT%% ==假设输入大小为(H,W)，滤波器大小为(FH,FW)，输出大小为(OH,OW)，填充为P，步幅为S。此时，输出大小可通过式(7.1)进行计算。== %%POSTFIX%%(7.1)现在，我们使用这个算式，试着做几个计算。例1：图7-*
>%%LINK%%[[#^dimmkozr7n5|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^dimmkozr7n5


>%%
>```annotation-json
>{"created":"2024-04-09T10:04:00.158Z","updated":"2024-04-09T10:04:00.158Z","document":{"title":"%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","link":[{"href":"urn:x-pdf:3cd36d714d46ee45a1ce3205394700f6"},{"href":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf"}],"documentFingerprint":"3cd36d714d46ee45a1ce3205394700f6"},"uri":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","target":[{"source":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","selector":[{"type":"TextPositionSelector","start":150583,"end":150630},{"type":"TextQuoteSelector","exact":"根据深度学习的框架的不同，当值无法除尽时，有时会向最接近的整数四舍五入，不进行报错而继续运行。","prefix":"大小无法除尽时（结果是小数时），需要采取报错等对策。顺便说一下，","suffix":"7.2.5 3维数据的卷积运算之前的卷积运算的例子都是以有高、长"}]}]}
>```
>%%
>*%%PREFIX%%大小无法除尽时（结果是小数时），需要采取报错等对策。顺便说一下，%%HIGHLIGHT%% ==根据深度学习的框架的不同，当值无法除尽时，有时会向最接近的整数四舍五入，不进行报错而继续运行。== %%POSTFIX%%7.2.5 3维数据的卷积运算之前的卷积运算的例子都是以有高、长*
>%%LINK%%[[#^908lv5nlh|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^908lv5nlh


>%%
>```annotation-json
>{"created":"2024-04-09T10:04:50.289Z","updated":"2024-04-09T10:04:50.289Z","document":{"title":"%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","link":[{"href":"urn:x-pdf:3cd36d714d46ee45a1ce3205394700f6"},{"href":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf"}],"documentFingerprint":"3cd36d714d46ee45a1ce3205394700f6"},"uri":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","target":[{"source":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","selector":[{"type":"TextPositionSelector","start":152659,"end":152683},{"type":"TextQuoteSelector","exact":"通过应用FN个滤波器，输出特征图也生成了FN个。","prefix":", OH, OW)CCFN输入数据 输出数据滤波器图7-11中，","suffix":"如果将这FN个特征图汇集在一起，就得到了形状为(FN,OH,OW"}]}]}
>```
>%%
>*%%PREFIX%%, OH, OW)CCFN输入数据 输出数据滤波器图7-11中，%%HIGHLIGHT%% ==通过应用FN个滤波器，输出特征图也生成了FN个。== %%POSTFIX%%如果将这FN个特征图汇集在一起，就得到了形状为(FN,OH,OW*
>%%LINK%%[[#^ahwa9kkby09|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^ahwa9kkby09


>%%
>```annotation-json
>{"created":"2024-04-09T10:26:31.065Z","updated":"2024-04-09T10:26:31.065Z","document":{"title":"%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","link":[{"href":"urn:x-pdf:3cd36d714d46ee45a1ce3205394700f6"},{"href":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf"}],"documentFingerprint":"3cd36d714d46ee45a1ce3205394700f6"},"uri":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","target":[{"source":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","selector":[{"type":"TextPositionSelector","start":130787,"end":130797},{"type":"TextQuoteSelector","exact":"这个问题称为梯度消失","prefix":"偏向0和1的数据分布会造成反向传播中梯度的值不断变小，最后消失。","suffix":"（gradient vanishing）。层次加深的深度学习中，"}]}]}
>```
>%%
>*%%PREFIX%%偏向0和1的数据分布会造成反向传播中梯度的值不断变小，最后消失。%%HIGHLIGHT%% ==这个问题称为梯度消失== %%POSTFIX%%（gradient vanishing）。层次加深的深度学习中，*
>%%LINK%%[[#^d8jbu0b33rw|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^d8jbu0b33rw


>%%
>```annotation-json
>{"created":"2024-04-09T10:26:35.143Z","updated":"2024-04-09T10:26:35.143Z","document":{"title":"%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","link":[{"href":"urn:x-pdf:3cd36d714d46ee45a1ce3205394700f6"},{"href":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf"}],"documentFingerprint":"3cd36d714d46ee45a1ce3205394700f6"},"uri":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","target":[{"source":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","selector":[{"type":"TextPositionSelector","start":131460,"end":131465},{"type":"TextQuoteSelector","exact":"表现力受限","prefix":"神经元来表达基本相同的事情。因此，激活值在分布上有所偏向会出现“","suffix":"”的问题。各层的激活值的分布都要求有适当的广度。为什么呢？因为通"}]}]}
>```
>%%
>*%%PREFIX%%神经元来表达基本相同的事情。因此，激活值在分布上有所偏向会出现“%%HIGHLIGHT%% ==表现力受限== %%POSTFIX%%”的问题。各层的激活值的分布都要求有适当的广度。为什么呢？因为通*
>%%LINK%%[[#^19e76ct3a8f|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^19e76ct3a8f


>%%
>```annotation-json
>{"created":"2024-04-09T10:26:54.926Z","updated":"2024-04-09T10:26:54.926Z","document":{"title":"%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","link":[{"href":"urn:x-pdf:3cd36d714d46ee45a1ce3205394700f6"},{"href":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf"}],"documentFingerprint":"3cd36d714d46ee45a1ce3205394700f6"},"uri":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","target":[{"source":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","selector":[{"type":"TextPositionSelector","start":131775,"end":131809},{"type":"TextQuoteSelector","exact":"推导出的结论是，如果前一层的节点数为n，则初始值使用标准差为 的分布","prefix":"的分布，推  第6章 与学习相关的技巧180导了合适的权重尺度。","suffix":"A （图6-12）。图6-12 Xavier初始值：与前一层有n"}]}]}
>```
>%%
>*%%PREFIX%%的分布，推  第6章 与学习相关的技巧180导了合适的权重尺度。%%HIGHLIGHT%% ==推导出的结论是，如果前一层的节点数为n，则初始值使用标准差为 的分布== %%POSTFIX%%A （图6-12）。图6-12 Xavier初始值：与前一层有n*
>%%LINK%%[[#^qiyivgj31r|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^qiyivgj31r


>%%
>```annotation-json
>{"created":"2024-04-09T10:29:03.752Z","updated":"2024-04-09T10:29:03.752Z","document":{"title":"%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","link":[{"href":"urn:x-pdf:3cd36d714d46ee45a1ce3205394700f6"},{"href":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf"}],"documentFingerprint":"3cd36d714d46ee45a1ce3205394700f6"},"uri":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","target":[{"source":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","selector":[{"type":"TextPositionSelector","start":134075,"end":134154},{"type":"TextQuoteSelector","exact":"当激活函数使用ReLU时，权重初始值使用He初始值，当激活函数为sigmoid 或tanh 等S型曲线函数时，初始值使用Xavier初始值。这是目前的最佳实践","prefix":"的广度也能保持不变，因此逆向传播时，也会传递合适的值。总结一下，","suffix":"。6.2.4 基于MNIST数据集的权重初始值的比较下面通过实际"}]}]}
>```
>%%
>*%%PREFIX%%的广度也能保持不变，因此逆向传播时，也会传递合适的值。总结一下，%%HIGHLIGHT%% ==当激活函数使用ReLU时，权重初始值使用He初始值，当激活函数为sigmoid 或tanh 等S型曲线函数时，初始值使用Xavier初始值。这是目前的最佳实践== %%POSTFIX%%。6.2.4 基于MNIST数据集的权重初始值的比较下面通过实际*
>%%LINK%%[[#^8rzhe5krbs|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^8rzhe5krbs


>%%
>```annotation-json
>{"created":"2024-04-22T13:27:55.547Z","updated":"2024-04-22T13:27:55.547Z","document":{"title":"%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","link":[{"href":"urn:x-pdf:3cd36d714d46ee45a1ce3205394700f6"},{"href":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf"}],"documentFingerprint":"3cd36d714d46ee45a1ce3205394700f6"},"uri":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","target":[{"source":"vault:/0.plugin/pdf/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf","selector":[{"type":"TextPositionSelector","start":132904,"end":132933},{"type":"TextQuoteSelector","exact":"当前一层的节点数为n时，He初始值使用标准差为 的高斯分布","prefix":"iming He等人推荐的初始值，也称为“He初始值”[10]。","suffix":"。当Xavier初始值是 时，（直观上）可以解释为，因为ReLU"}]}]}
>```
>%%
>*%%PREFIX%%iming He等人推荐的初始值，也称为“He初始值”[10]。%%HIGHLIGHT%% ==当前一层的节点数为n时，He初始值使用标准差为 的高斯分布== %%POSTFIX%%。当Xavier初始值是 时，（直观上）可以解释为，因为ReLU*
>%%LINK%%[[#^7tgssjwjy2h|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^7tgssjwjy2h
